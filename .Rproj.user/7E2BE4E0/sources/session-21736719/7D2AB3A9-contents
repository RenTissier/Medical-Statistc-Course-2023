---
title: "Make power illustrations"
author: "Renee Menezes"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Rejection regions and power

In the current course material, we are just talking about what the power is. But it would be nice to illustrate what the power is. For this we could use shading under curves.


### Colouring under curves

The example below uses the function `polygon()`.

```{r}
x <- seq(-3.5, 3.5, length=100)
y <- dnorm(x)
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under the null hypothesis")
# Get quantile for 0.05 upper-tail prob of a standard normal
x.up <- qnorm(0.95)
# create a red colour with some transparency
redt <- rgb(red = 1, green = 0, blue = 0, alpha = 0.5)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
legend("topleft", legend = "rejection region", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
text(x.up, max(y) - .1*diff(range(y)), "Critical level", pos = 4)
```


### Illustrating two-sided critical regions

We now use the same sets of parameters as used in chapter 2 to illustrate power. For `variableX`, we had the standard normal for group `A` and a mean 2 for group `B`. We don't know in advance that values in group `B` are all larger than those in group `A`, so we use a two-sided test to compare the 2 groups. The distribution of the values under the null hypothesis is a Student-t with 20-2 degrees of freedom, and the probability density function for it, with the rejection regions, is given below. Here we use $\alpha = 0.05$, so we assign half of that probability of making a type-I error to each tail.

```{r}
x <- seq(from = -5, to = 5, by = 0.01)
df <- 20-2
y <- dt(x, df = df)
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under the null hypothesis", 
     ylim = c(0, max(y) + .1*diff(range(y))))
# Get quantile for 0.05 upper-tail prob of a standard normal
x.up <- qt(0.975, df = df)
x.lo <- qt(0.025, df = df)
# create a red colour with some transparency
redt <- rgb(red = 1, green = 0, blue = 0, alpha = 0.5)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
polygon(c(min(x), x[ x <= x.lo ], x.lo), c(0, y[ x <= x.lo], 0), col = redt)
legend("topleft", legend = "rejection regions", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
text(x.up, max(y) - .1*diff(range(y)), "critical level", pos = 4)
segments(x.lo, 0, x.lo, max(y), lty = "dashed", col = "gray", lwd = 2)
text(x.lo, max(y) - .1*diff(range(y)), "critical level", pos = 2)

```

### Illustrating the power

Say we now want to be able to detect an effect size of 2, given that the variance in the second group is the same as in the first group. To compute the power, we evaluate the probability of rejecting the null hypothesis, if the data is generated according to the data distribution under the alternative hypothesis. Here we use only a positive effect size, for illustration.

First we make the graph of the probability density functions under the null and the alternative hypotheses.

```{r}
y.a <- dt(x, df = df, ncp = 2)
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under different hypotheses", 
     ylim = c(0, max(y) + .1*diff(range(y))), lwd = 2)
lines(x, y.a, col = "blue", lwd = 2)
legend("topleft", legend = c("Null", "Alternative"), lty = "solid", lwd = 2,
       col = c("black", "blue"))
```

Let us now add the critical regions.


```{r}
y.a <- dt(x, df = df, ncp = 2)
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under different hypotheses", 
     ylim = c(0, max(y) + .1*diff(range(y))), lwd = 2)
lines(x, y.a, col = "blue", lwd = 2)
legend("topleft", legend = c("Null", "Alternative"), lty = "solid", lwd = 2,
       col = c("black", "blue"))
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
polygon(c(min(x), x[ x <= x.lo ], x.lo), c(0, y[ x <= x.lo], 0), col = redt)
legend("topright", legend = "rejection regions", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
segments(x.lo, 0, x.lo, max(y), lty = "dashed", col = "gray", lwd = 2)


```

Then the power is the probability of rejecting the null hypothesis, i.e. obtaining a value in a critical region, if the data is generated by the distribution under the alternative (in blue):

```{r}
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under different hypotheses", 
     ylim = c(0, max(y) + .1*diff(range(y))), lwd = 2)
lines(x, y.a, col = "blue", lwd = 2)
legend("topleft", legend = c("Null", "Alternative"), lty = "solid", lwd = 2,
       col = c("black", "blue"))
# create a red colour with some transparency
bluet <- rgb(red = 0, green = 0, blue = 1, alpha = 0.5)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
polygon(c(min(x), x[ x <= x.lo ], x.lo), c(0, y[ x <= x.lo], 0), col = redt)
legend("topright", legend = "rejection regions", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
segments(x.lo, 0, x.lo, max(y), lty = "dashed", col = "gray", lwd = 2)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y.a[ x >= x.up], 0, 0), col = bluet)
legend("bottomleft", legend = "power", fill = bluet)


```

### What happens if the effect size is smaller?

In the example, `variableY` had values in group `B` generated with an effect size of 0.3. Let us now compare the power obtained with an effect size of 2, as those for `variableX`, with those for this smaller effect size. First we plot only the probability density functions:

```{r}
y.a <- dt(x, df = df, ncp = .3)
plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under different hypotheses", 
     ylim = c(0, max(y) + .1*diff(range(y))), lwd = 2)
lines(x, y.a, col = "blue", lwd = 2)
legend("topleft", legend = c("Null", "Alternative"), lty = "solid", lwd = 2,
       col = c("black", "blue"))
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
polygon(c(min(x), x[ x <= x.lo ], x.lo), c(0, y[ x <= x.lo], 0), col = redt)
legend("topright", legend = "rejection regions", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
segments(x.lo, 0, x.lo, max(y), lty = "dashed", col = "gray", lwd = 2)


```

Now we colour the area corresponding to the power:

```{r}

plot(x, y, type="l", xlab = "variable values", ylab = "density", 
     main = "Distribution of X under different hypotheses", 
     ylim = c(0, max(y) + .1*diff(range(y))), lwd = 2)
lines(x, y.a, col = "blue", lwd = 2)
legend("topleft", legend = c("Null", "Alternative"), lty = "solid", lwd = 2,
       col = c("black", "blue"))
# create a red colour with some transparency
bluet <- rgb(red = 0, green = 0, blue = 1, alpha = 0.5)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y[ x >= x.up], 0, 0), col = redt)
polygon(c(min(x), x[ x <= x.lo ], x.lo), c(0, y[ x <= x.lo], 0), col = redt)
legend("topright", legend = "rejection regions", fill = redt)
segments(x.up, 0, x.up, 1, lty = "dashed", col = "gray", lwd = 2)
segments(x.lo, 0, x.lo, max(y), lty = "dashed", col = "gray", lwd = 2)
polygon(c(x[ x >= x.up ], max(x), x.up), c(y.a[ x >= x.up], 0, 0), col = bluet)
legend("bottomleft", legend = "power", fill = bluet)


```

## qqplot: normal and other distributions

Let us generate data according to a normal distribution as well as a asymetric one.

```{r}
mymean <- 3
myvar <- 1.5
x <- seq(from = 0, to = 8, by = 0.01)
ynorm <- dnorm(x, mean = mymean, sd = sqrt(myvar))
ygam <- dgamma(x, shape = ((mymean+1)^2)/myvar, rate = (mymean+1)/myvar)
plot(x, ynorm, type = "l", col = "blue", lwd = 2, ylim = range(c(ynorm, ygam)))
lines(x, ygam, col = "purple", lwd = 2)
legend("topright", legend = c("normal", "gamma"), lty = "solid", lwd = 2,
       col = c("blue", "purple"))
```


Now simulate data according to these distributions and make the qqplots to compare the obtained empirical distribution to the normal distribution:

```{r}
nsam <- 100
xnorm <- rnorm(nsam, mean = mymean, sd = sqrt(myvar))
xgam <- rgamma(nsam, shape = ((mymean+1)^2)/myvar, rate = (mymean+1)/myvar)
par(mfrow = c(1, 2))
qqnorm(xnorm, pch = 1, frame = FALSE)
qqline(xnorm, col = "blue", lwd = 2)

qqnorm(xgam, pch = 1, frame = FALSE)
qqline(xgam, col = "purple", lwd = 2)
```

Now an example with more asymetry:




```{r}
mymean <- 3
myvar <- 1.5
x <- seq(from = 0.01, to = 8, by = 0.01)
ynorm <- dnorm(x, mean = mymean, sd = sqrt(myvar))
ygam <- dgamma(x, shape = 1, rate = 2)
plot(x, ynorm, type = "l", col = "blue", lwd = 2, ylim = range(c(ynorm, ygam)))
lines(x, ygam, col = "purple", lwd = 2)
legend("topright", legend = c("normal", "gamma"), lty = "solid", lwd = 2,
       col = c("blue", "purple"))
```


Now simulate data according to these distributions and make the qqplots to compare the obtained empirical distribution to the normal distribution:

```{r}
nsam <- 100
xnorm <- rnorm(nsam, mean = mymean, sd = sqrt(myvar))
xgam <- rgamma(nsam, shape = 1, rate = 2)
par(mfrow = c(1, 2))
qqnorm(xnorm, pch = 1, frame = FALSE)
qqline(xnorm, col = "blue", lwd = 2)

qqnorm(xgam, pch = 1, frame = FALSE)
qqline(xgam, col = "purple", lwd = 2)
```

