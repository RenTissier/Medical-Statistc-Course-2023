"0","#' @title cv.glmmLasso"
"0","#' @description Does k-fold cross validation for glmmLasso  "
"0","#' @details Build multiple models given a sequence of lambda values"
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @export"
"0","#' @importFrom dplyr ""%>%"""
"0","#' @param fix A two-sided linear formula object describing the fixed-effects part of the model, with the response on the left of a ~ operator and the terms, separated by + operators, on the right. For categorical covariables use as.factor(.) in the formula. Note, that the corresponding dummies are treated as a group and are updated blockwise"
"0","#' @param rnd A two-sided linear formula object describing the random-effects part of the model, with the grouping factor on the left of a ~ operator and the random terms, separated by + operators, on the right; aternatively, the random effects design matrix can be given directly (with suitable column names). If set to NULL, no random effects are included."
"0","#' @param data The data frame containing the variables named in formula."
"0","#' @param family A GLM family, see [glm()] and [family()]. Also ordinal response models can be fitted: use family=acat() and family=cumulative() for the fitting of an adjacent category or cumulative model, respectively. If family is missing then a linear mixed model is fit; otherwise a generalized linear mixed model is fit."
"0","#' @param kfold Number of folds - default is 10. Although k-folds can be as large as the sample size (leave-one-out CV), it is not recommended for large datasets. Smallest value allowable is nfolds = 3"
"0","#' @param lambdas Optional user-supplied lambda sequence; default is NULL, and glmmLasso_MultLambdas chooses its own sequence"
"0","#' @param nlambdas The number of lambdas values, default value is 100 if lambdas is not user-supplied"
"0","#' @param lambda.min.ratio Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs > nvars, the default is 0.0001, close to zero. If nobs < nvars, the default is 0.01."
"0","#' @param loss Loss function used to calculate error, default values is based on family: \cr"
"0","#' "
"0","#' \itemize{"
"0","#' \item gaussian = [cv.glmmLasso::calc_mse()] "
"0","#' \item binomial = [cv.glmmLasso::calc_logloss()] "
"0","#' \item multinomial = [cv.glmmLasso::calc_multilogloss()] "
"0","#' \item poisson = [cv.glmmLasso::calc_deviance()]"
"0","#'   }"
"0","#' "
"0","#' @param lambda.final Choice for final model to use lambda.1se or lambda.min, default is lambda.1se"
"0","#' @param \dots can receive parameters accepted by glmmLasso"
"0","#' @md"
"0","#' @return A list of cross-validation values including: \cr "
"0","#' "
"0","#' "
"0","#' \describe{"
"0","#' \item{lambdas}{The values of lambda used in the fits} "
"0","#' \item{cvm}{The mean cross-validated error - a vector of length length(lambda)} "
"0","#' \item{cvsd}{Estimate of standard error of cvm.}"
"0","#' \item{cvup}{Upper curve = cvm+cvsd.}"
"0","#' \item{cvlo}{Lower curve = cvm-cvsd.} "
"0","#' \item{glmmLasso.final}{A fitted glmmLasso object for the full data} "
"0","#' \item{lambda.min}{Value of lambda that gives minimum cvm} "
"0","#' \item{lambda.1se}{Largest value of lambda such that error is within 1 standard error of the minimum}"
"0","#' }"
"0","#' "
"0","#' "
"0","#' @examples "
"0","#' data(""soccer"", package = ""glmmLasso"")"
"0","#' soccer[,c(4,5,9:16)]<-scale(soccer[,c(4,5,9:16)],center=TRUE,scale=TRUE)"
"0","#' soccer <- data.frame(soccer)"
"0","#' "
"0","#' mod1 <- cv.glmmLasso(fix = points ~ transfer.spendings + ave.unfair.score + "
"0","#' ball.possession + tackles, rnd = list(team=~1), data = soccer, "
"0","#' family = gaussian(link = ""identity""), kfold = 5, lambda.final = 'lambda.1se')"
"0",""
"0",""
"0","cv.glmmLasso <- function(fix, rnd, data, "
"0","                         family = stats::gaussian(link = ""identity""), "
"0","                         kfold = 5, lambdas = NULL, nlambdas = 100, "
"0","                         lambda.min.ratio = ifelse(nobs < nvars, 0.01, 0.0001), "
"0","                         loss,"
"0","                         lambda.final=c('lambda.1se', 'lambda.min'),"
"0","                         ...)"
"0","{"
"0","    lambda.final <- match.arg(lambda.final)"
"0","    "
"0","    if(missing(loss))"
"0","    {"
"0","        # switch allows us to do take the family arg as assign the appropriate "
"0","        # loss function "
"0","        loss <- switch(family$family, "
"0","                       'gaussian' = calc_mse,"
"0","                       'binomial' = calc_logloss,"
"0","                       'multinomial' = calc_multilogloss,"
"0","                       'poisson' = calc_deviance)"
"0","    }"
"0","    "
"0","    x <- useful::build.x(fix, data)"
"0","    nobs <- nrow(x)"
"0","    nvars <- ncol(x)"
"0","    "
"0","    # if lambda isn't specified by user, build the lambdas vector, this is "
"0","    # static for all k folds"
"0","    if (is.null(lambdas))"
"0","    {"
"0","        # building the lambda vector"
"0","        lambdas <- buildLambdas(fix = fix,"
"0","                                rnd = rnd,"
"0","                                data = data, "
"0","                                nlambdas = nlambdas, "
"0","                                lambda.min.ratio= lambda.min.ratio)   "
"0","    }"
"0","    "
"0","    "
"0","    "
"0","    "
"0","    # building data frame to map a specific row to kth group"
"0","    # column 1 is the row, column 2 is a randomly assigned group"
"0","    # number of groups is determined by kfold value  "
"0","    rowDF <- tibble::tibble("
"0","        row = seq(nobs),"
"0","        group = sample(rep(seq(kfold), length.out=nobs), replace = FALSE)"
"0","    )"
"0","    "
"0","    # sorting by group "
"0","    rowDF <-  dplyr::arrange(rowDF, .data$group)"
"0","    "
"0","    "
"0","    #instantiating list to hold loss and models for each fold"
"0","    lossVecList <- vector(mode = 'list', length = kfold)"
"0","    modList_foldk <- vector(mode = 'list', length = kfold)"
"0","    "
"0","    for(k in 1:kfold)"
"0","    {"
"0","        testIndices <- dplyr::filter(rowDF, .data$group == k) %>% dplyr::pull(row)"
"0","        trainIndices <- rowDF$row[-testIndices]"
"0","        "
"0","        # fitting model"
"0","        # modList_foldk is a glmmLasso_MultLambdas object, which is a list of "
"0","        # glmmLasso objects"
"0","        "
"0","        # for showing lambda at each iterations"
"0","        # message(sprintf('Round: %s\n ', k))"
"0","        modList_foldk[[k]] <- glmmLasso_MultLambdas(fix = fix,"
"0","                                                    rnd = rnd,"
"0","                                                    data = data %>% dplyr::slice(trainIndices),"
"0","                                                    family = family,"
"0","                                                    lambdas = lambdas,"
"0","                                                    nlambdas = nlambdas,"
"0","                                                    lambda.min.ratio = lambda.min.ratio,"
"0","                                                    ...)"
"0","        "
"0","        "
"0","        "
"0","        # hacky way of getting the response variable out of the         "
"0","        response_var <- fix[[2]] %>% as.character()"
"0","        "
"0","        # pulling out actual data"
"0","        actualDataVector <- data %>% dplyr::slice(testIndices) %>% "
"0","            dplyr::pull(response_var)"
"0","        "
"0","        # predicting values for each of the glmmLasso model (100 lambda) "
"0","        # using matrix form for easier error calculation in loss()"
"0","        "
"0","        predictionMatrix <- predict.glmmLasso_MultLambdas("
"0","            object = modList_foldk[[k]],"
"0","            newdata = data %>% dplyr::slice(testIndices)"
"0","        )"
"0","        "
"0","        # employing the loss function in form loss(actual,predicted)"
"0","        # using loss function, calculating a list of loss values for each vector "
"0","        # of prediction"
"0","        # which comes from a glmmLasso model with a specific lambda "
"0","        # storing loss values for each fold"
"0","        "
"0","        # TODO: think an error is thrown here "
"0","        lossVecList[[k]] <- loss(actual = actualDataVector, predicted = predictionMatrix)"
"0","        # each element of this list should be 1 x nlambdas"
"0","    }"
"0","    "
"0","    #building matrix (k by nlambdas) to help calculate cross-validated mean error"
"0","    cvLossMatrix <- do.call(what = rbind, args = lossVecList)"
"0","    "
"0","    cvm = colMeans(cvLossMatrix)"
"0","    "
"0","    # calculating sd, cv, up, down"
"0","    cvsd <- apply(cvLossMatrix, 2, stats::sd, na.rm = TRUE)"
"0","    cvup <- cvm + cvsd"
"0","    cvlo <- cvm - cvsd"
"0","    "
"0","    "
"0","    # finding the minimum cvm value in order pull out the lambda.min out of "
"0","    # list of lambda"
"0","    minIndex <- which.min(cvm)    "
"0","    lambda.min <- lambdas[minIndex]"
"0","    "
"0","    # finding 1se index by doing vectorized comparision such that cvm <= cvup "
"0","    # of minIndex"
"0","    my1seIndex <- min(which(cvm <= cvup[minIndex]))"
"0","    lambda.1se <- lambdas[my1seIndex]"
"0","    "
"0","    # chosing lambda.final to use by checking lambda.final option"
"0","    # note that first element lambda.final default value will return true for"
"0","    # lambda.1se "
"0","    chosenLambda <- if(lambda.final == 'lambda.1se')"
"0","    {"
"0","        lambda.1se"
"0","    }else if(lambda.final == 'lambda.min')"
"0","    {"
"0","        lambda.min"
"0","    }"
"0","    "
"0","    "
"0","    "
"0","    glmmLasso.final <- glmmLasso::glmmLasso(fix = fix,"
"0","                                            rnd = rnd,"
"0","                                            data = data,"
"0","                                            family = family,"
"0","                                            lambda = chosenLambda)"
"0","    "
"0","    # add control list argument to this to make converge faster form one that "
"0","    # create lambda.1se"
"0","    # TODO: (maybe) For final model fit, supply control list from the model that led to     either lambda.1se or lambda.min"
"0","    "
"0","    # mimicking cv.glmnet return objects"
"0","    return_List <- list(lambdas=lambdas,"
"0","                        cvm=cvm,"
"0","                        cvsd=cvsd,"
"0","                        cvup=cvup,"
"0","                        cvlo=cvlo,"
"0","                        glmmLasso.final=glmmLasso.final,"
"0","                        lambda.min=lambda.min,"
"0","                        lambda.1se=lambda.1se)"
"0","    "
"0","    "
"0","    class(return_List) <- 'cv.glmmLasso'"
"0","    "
"0","    "
"0","    return(return_List)"
"0","    "
"0","}"
"0",""
"0",""
"0","# modified from calc.deviance in dismo package - credit to Robert Hijmans"
"0",""
"0","#' "
"0","#' @title calc_mse"
"0","#' @description Function for calculating mse"
"0","#' @details Loss functions written for use in cv.glmmLasso "
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param actual actual data values "
"0","#' @param predicted predicted data values"
"0","#' @return error between actual versus prediction"
"0","#'"
"0",""
"0","calc_mse <- function(actual, predicted)"
"0","{"
"0","    return(colMeans((actual - predicted)^2)) "
"0","}"
"0",""
"0","#' "
"0","#' @title calc_logloss"
"0","#' @description Functions for calculating logloss"
"0","#' @details Loss functions written for use in cv.glmmLasso "
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param actual actual data values "
"0","#' @param predicted predicted data values"
"0","#' @return error between actual versus prediction"
"0","#'"
"0","calc_logloss <- function(actual, predicted)"
"0","{"
"0","    "
"0","    score <- -(actual * log(predicted) + (1 - actual) * log(1 -predicted))"
"0","    score[actual == predicted] <- 0"
"0","    score[is.nan(score)] <- Inf"
"0","    return(colMeans(score))"
"0","    "
"0","}"
"0",""
"0","#' "
"0","#' @title calc_multilogloss"
"0","#' @description Function for calculating multilogloss"
"0","#' @details loss functions written for use in cv.glmmLasso "
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param actual actual data values "
"0","#' @param predicted predicted data values"
"0","#' @return error between actual versus prediction"
"0","#'"
"0",""
"0","# modified from MultiLogLoss in MLMetrics package - credit to Yachen Yan"
"0",""
"0","calc_multilogloss <- function(actual, predicted) "
"0","{"
"0","    return(apply(predicted, 2, MLmetrics::MultiLogLoss, y_true = actual)) "
"0","}"
"0",""
"0",""
"0","#' "
"0","#' @title calc_deviance"
"0","#' @description Functions for calculating deviance"
"0","#' @details loss functions written for use in cv.glmmLasso "
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param actual actual data values "
"0","#' @param predicted predicted data values"
"0","#' @param family default value is poisson"
"0","#' @param \dots can receive parameters accepted by dismo::calc.deviance"
"0","#' @return error between actual versus prediction"
"0","#'"
"0","calc_deviance <- function(actual, predicted, family = 'poisson',...)"
"0","{"
"0","    "
"0","    return(apply(predicted, 2, dismo::calc.deviance, obs = actual, family = family,"
"0","                 ...))"
"0","}"
"0",""
"0","# this function compute the max lambda based on formula given"
"0",""
"0","#' @title computeLambdaMax"
"0","#' @description compute the maximum lambda value based on given dataset "
"0","#' @details lambdaMax is computed based on  the coordinate descent algorithm from this paper: Friedman, Jerome, Trevor Hastie, and Rob Tibshirani. ""Regularization paths for generalized linear models via coordinate descent."""
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param fix A two-sided linear formula object describing the fixed-effects part of the model, with the response on the left of a ~ operator and the terms, separated by + operators, on the right. For categorical covariables use as.factor(.) in the formula. Note, that the corresponding dummies are treated as a group and are updated blockwise"
"0","#' @param rnd A two-sided linear formula object describing the random-effects part of the model, with the grouping factor on the left of a ~ operator and the random terms, separated by + operators, on the right; aternatively, the random effects design matrix can be given directly (with suitable column names). If set to NULL, no random effects are included."
"0","#' @param data The data frame containing the variables named in formula."
"0","#' @param scale default value is true"
"0","#' @return returns the lambdaMax value based on given dataset"
"0",""
"0",""
"0","computeLambdaMax <- function(fix, rnd, data, scale=TRUE)"
"0","{"
"0","    # converting formula into matrices to do lambdaMax calculation"
"0","    y <- useful::build.y(fix, data)"
"0","    x <- useful::build.x(fix, data)"
"0","    "
"0","    if(scale)"
"0","    {"
"0","        x <- scale(x)"
"0","    }"
"0","    "
"0","    # exp because of log scale"
"0","    # N*alpha*lambdaMax = max_l(<x_l, y>)"
"0","    lambdaMax <- exp(max(abs(colSums(x*y)), na.rm=TRUE) / nrow(data))"
"0","    "
"0","    # colSums(x*y) is same as crossprod(x,y)"
"0","    "
"0","    return(lambdaMax)"
"0","}"
"0",""
"0","#' @title buildLambdas"
"0","#' @description generate lambda vector based on dataset given"
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @param fix A two-sided linear formula object describing the fixed-effects part of the model, with the response on the left of a ~ operator and the terms, separated by + operators, on the right. For categorical covariables use as.factor(.) in the formula. Note, that the corresponding dummies are treated as a group and are updated blockwise"
"0","#' @param rnd A two-sided linear formula object describing the random-effects part of the model, with the grouping factor on the left of a ~ operator and the random terms, separated by + operators, on the right; alternatively, the random effects design matrix can be given directly (with suitable column names). If set to NULL, no random effects are included."
"0","#' @param data The data frame containing the variables named in formula."
"0","#' @param nlambdas the number of lambdas values, default value is 100 if lambdas is not user-supplied"
"0","#' @param lambda.min.ratio Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs > nvars, the default is 0.0001, close to zero. If nobs < nvars, the default is 0.01."
"0","#' @return returns a vector of lambda"
"0","#'"
"0",""
"0",""
"0","buildLambdas <- function(fix, rnd, data, "
"0","                         nlambdas = 100, "
"0","                         lambda.min.ratio = ifelse(nobs < nvars, 0.01, 0.0001))"
"0","{"
"0","    # converting formula into matrices to do lambdaMax calculation"
"0","    x <- useful::build.x(fix, data)"
"0","    nobs <- nrow(x)"
"0","    nvars <- ncol(x)"
"0","    "
"0","    lambdaMax = computeLambdaMax(fix = fix, "
"0","                                 rnd = rnd,"
"0","                                 data = data)"
"0","    "
"0","    lambda_vec <- seq(from = lambdaMax, "
"0","                      to = lambdaMax * lambda.min.ratio, "
"0","                      length.out = nlambdas) "
"0","    # sorting such that first lambda is the largest"
"0","    lambda_vec <- sort(lambda_vec, decreasing = TRUE)"
"0","    "
"0","    return(lambda_vec)"
"0","}"
"0",""
"0",""
"0","#' @title glmmLasso_MultLambdas"
"0","#' @description Variable selection using glmmLasso for multiple lambdas values  "
"0","#' @details Build multiple models given a sequence of lambda values"
"0","#' @author Pirapong Jitngamplang, Jared Lander"
"0","#' @export"
"0","#' @param fix A two-sided linear formula object describing the fixed-effects part of the model, with the response on the left of a ~ operator and the terms, separated by + operators, on the right. For categorical covariables use as.factor(.) in the formula. Note, that the corresponding dummies are treated as a group and are updated blockwise"
"0","#' @param rnd A two-sided linear formula object describing the random-effects part of the model, with the grouping factor on the left of a ~ operator and the random terms, separated by + operators, on the right; aternatively, the random effects design matrix can be given directly (with suitable column names). If set to NULL, no random effects are included."
"0","#' @param data The data frame containing the variables named in formula."
"0","#' @param family a GLM family, see glm and family. Also ordinal response models can be fitted: use family=acat() and family=cumulative() for the fitting of an adjacent category or cumulative model, respectively. If family is missing then a linear mixed model is fit; otherwise a generalized linear mixed model is fit."
"0","#' @param lambdas The penalty parameter that controls the shrinkage of fixed terms and controls the variable selection. The optimal penalty parameter is a tuning parameter of the procedure that has to be determined, e.g. by use of information criteria or cross validation. Should inputted as a numeric vector from high to low. (See details for an example.)"
"0","#' @param nlambdas the number of lambdas values, default value is 100."
"0","#' @param lambda.min.ratio Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs > nvars, the default is 0.0001, close to zero. If nobs < nvars, the default is 0.01."
"0","#' @param \dots can receive parameters accepted by glmmLasso"
"0","#' @return Returns a glmmLasso_MultLambdas object, which is list glmmLasso models for each lambda value.  "
"0","#' @examples"
"0","#' "
"0","#' library(glmmLasso)"
"0","#' data(""soccer"")"
"0","#' "
"0","#' mod1 <- glmmLasso_MultLambdas(fix = points ~ transfer.spendings + "
"0","#' ball.possession + tackles , rnd = list(team =~ 1), "
"0","#' data = soccer, family = poisson(link = log)) "
"0","#' "
"0","#' "
"0","#'  "
"0",""
"0","glmmLasso_MultLambdas <- function(fix, rnd, data, "
"0","                                  family = stats::gaussian(link = ""identity""), "
"0","                                  lambdas = NULL,"
"0","                                  nlambdas = 100,"
"0","                                  lambda.min.ratio=ifelse(nobs < nvars, 0.01, 0.0001), "
"0","                                  ...)"
"0","{"
"0","    "
"0","    # fitting first model to generate initial inputs for control parameter"
"0","    # here we use the first lambda (highest penalty) to start"
"0","    # based glmmLasso's author, glmmLasso is faster when final coefficient"
"0","    # estimates corresponding to a lambda is used as the starting value for"
"0","    # the next smaller lambda  "
"0","    "
"0","    # defining the number of observation"
"0","    nobs <- nrow(data)"
"0","    "
"0","    # defining the number of preditors based on the number of terms in fix formula"
"0","    nvars <- length(attr(stats::terms(fix), 'term.labels'))"
"0","    "
"0","    if (is.null(lambdas))"
"0","    {"
"0","        "
"0","        # building the lambda vector"
"0","        lambdas <- buildLambdas(fix = fix,"
"0","                                rnd = rnd,"
"0","                                data = data, "
"0","                                nlambdas = nlambdas, "
"0","                                lambda.min.ratio = lambda.min.ratio)    "
"0","    }"
"0","    "
"0","    "
"0","    "
"0","    # passing Q.start and Delta.start is modeled from glmmLasso demo file"
"0","    # from the ""More Elegant section"" "
"0","    "
"0","    # Delta is matrix containing the estimates of fixed and random effects "
"0","    # (columns) for each iteration (rows) of the main algorithm (i.e. before "
"0","    # the final re-estimation step is performed, see details)."
"0","    # Passing the set of estimates from the last iteration as the "
"0","    # 'start' parameter of the controlList"
"0","    "
"0","    # Q_long is a list containing the estimates of the random effects"
"0","    # variance-covariance parameters for each iteration of the main algorithm."
"0","    # Passing the variance-covaiance matrix as the q_start parameter of"
"0","    # the controlList"
"0","    "
"0","    "
"0","    "
"0","    # initializing list of object to hold the model outputs "
"0","    modList <- vector(mode = 'list', length = length(lambdas))"
"0","    "
"0","    "
"0","    # fit first lambda"
"0","    first_fit <- glmmLasso::glmmLasso(fix = fix,"
"0","                                      rnd = rnd,"
"0","                                      data = data,"
"0","                                      family = family,"
"0","                                      lambda = lambdas[1],"
"0","                                      ...)"
"0","    # builing the first Delta.start, transpose required to make dimension"
"0","    "
"0","    Delta.start <- first_fit$Deltamatrix[first_fit$conv.step, ] %>% t()"
"0","    Q.start <- first_fit$Q_long[[first_fit$conv.step + 1]]"
"0","    "
"0","    for (l in seq_along(lambdas))"
"0","    {"
"0","        "
"0","        # for showing lambda at each iteration"
"0","        # message(sprintf('Lambda: %s\n ', lambdas[l]))"
"0","        "
"0","        fit <- glmmLasso::glmmLasso(fix = fix,"
"0","                                    rnd = rnd,"
"0","                                    data = data,"
"0","                                    family = family,"
"0","                                    lambda = lambdas[l],"
"0","                                    control = list(start=Delta.start[l,],"
"0","                                                   q_start=Q.start[l]),...)"
"0","        "
"0","        # storing model objects before storing to modList"
"0","        fit$lambda <- lambdas[l]"
"0","        fit$Delta.start <- Delta.start[l,]"
"0","        fit$Q.start <- Q.start[l]"
"0","        fit$data <- data"
"0","        fit$rnd <- rnd"
"0","        fit$fix <- fix"
"0","        fit$family <- family"
"0","        "
"0","        modList[[l]] <- fit"
"0","        Delta.start <- rbind(Delta.start, fit$Deltamatrix[fit$conv.step, ])"
"0","        Q.start <- c(Q.start, fit$Q_long[[fit$conv.step + 1]])"
"0","        "
"0","        "
"0","        "
"0","    }"
"0","    "
"0","    # the function returns a list of glmmLasso models "
"0","    "
"0","    attr(modList, 'lambdas') <- lambdas"
"0","    "
"0","    class(modList) <- 'glmmLasso_MultLambdas'"
"0","    "
"0","    return(modList)"
"0","}"
"0",""
"0",""
"0",""
"0","predict.glmmLasso_MultLambdas <- function(object, newdata, ...)"
"0","{"
"0","    # instantiating list to hold nlambdas number of n x 1 vectors "
"0","    # pred_vec_list <- vector(mode = 'list', length = length(object))"
"0","    # storing returned vectors in a list "
"0","    "
"0","    pred_vec_list <- purrr::map(.x = object, .f = stats::predict, "
"0","                                newdata = newdata)"
"0","    "
"0","    pred_matrix <- do.call(what = cbind, args = pred_vec_list)"
"0","    "
"0","    return(pred_matrix)"
"0","}"
